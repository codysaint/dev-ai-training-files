{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Exercise - Advanced Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've learned to do linear algebra with NumPy. In this exercise set, we will get some real practice with the techniques we have learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:  Importing Numpy and the Linear Algebra Submodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NumPy and the linalg submodule separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy and linalg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Diagonal and Orthogonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some practice with diagonal and orthogonal matrices. First of all, create the following matrices: \n",
    "\n",
    "$$D = \\begin{bmatrix} 12 & 0 & 0 \\\\ 0 & -2 & 0 \\\\ 0 & 0 & 3\\end{bmatrix}, \\qquad O = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & -1 & 0\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the two matrices above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the transpose O^T is the same as the inverse O^(-1) by using the np.isclose function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: A Family of Orthogonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any number $r$ the matrix \n",
    "\n",
    "$$O_{r} = \\begin{bmatrix} \\cos(r) & \\sin(r)  \\\\ -sin(r) & \\cos(r) \\end{bmatrix}$$\n",
    "\n",
    "is an orthogonal matrix. The matrix $O_{r}$ represents a rotation around the origin with angle $r$. Let us build $O_{1}$ and verify numerically that $O_{1}$ is an orthogonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the matrix $Q_{1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that Q_1 is orthogonal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know trigonometry, then you can try to verify mathematically that $Q_{r}$ is orthogonal for any $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the QR decomposition is a way to write any matrix $A$ as $A = QR$, where $Q$ is orthogonal and $R$ is upper-triangular. Let us do this for an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T MODIFY THIS CELL, ONLY RUN IT.\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "camera = data.camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a QR decomposition of the camera image. Call the orthogonal part Q and upper-triangular part R.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image represented by Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image represented by R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the values in $Q$ and $R$ seems completely unrelated to those in $A$, and do not seem to produce images that show anything worthwhile. Nevertheless, all the necessary information are there. \n",
    "\n",
    "Try to show the product $QR$ as an image to see that we have not lost any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Least Squares to Approximate a Function (Challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common problem is to approximate complex data with simple functions. Say we have the function\n",
    "\n",
    "$$f(t) = e^{t^2} + \\cos(3t)$$\n",
    "\n",
    "where $t$ takes values between $0$ and $1$. \n",
    "\n",
    "How can we approximate the function $f(t)$ with a second-degree polynomial? Well, we can first evaluate the function $f(t)$ in the $101$ points between $0$ and $1$ given by\n",
    "\n",
    "$$t = \\begin{bmatrix} t_{0} \\\\ t_{1} \\\\ \\vdots \\\\ t_{99} \\\\ t_{100}\\end{bmatrix} = \\begin{bmatrix} 0.00 \\\\ 0.01 \\\\ \\vdots \\\\ 0.99 \\\\ 1.00\\end{bmatrix}.$$\n",
    "\n",
    "Then we get the vector \n",
    "\n",
    "$$y = \\begin{bmatrix} f(t_{0}) \\\\ f(t_{1}) \\\\ \\vdots \\\\ f(t_{99}) \\\\ f(t_{100})\\end{bmatrix} = \\begin{bmatrix} f(0.00) \\\\ f(0.01) \\\\ \\vdots \\\\ f(0.99) \\\\ f(1.00)\\end{bmatrix}$$\n",
    "\n",
    "The goal is to find the BEST second-degree polynomial\n",
    "\n",
    "$$p(t) = a_{0} + a_{1}t + a_{2}t^{2},$$ \n",
    "\n",
    "that approximates $f(t)$. How do we choose the coefficients $a_{0}, a_{1}, a_{2}$? Let us make the vector \n",
    "\n",
    "$$x = \\begin{bmatrix} a_{0} \\\\ a_{1} \\\\ a_{2}\\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5a:\n",
    "Before we explain how to find $x$, let us set up some of the variables we have defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need 101 points between 0 and 1. Use np.linspace and save it to a variable called \"t_values\".\n",
    "\n",
    "# We need the vector y described above. Make it by using np.exp, np.cos, and the \"points\" variable above.\n",
    "# Call the variable \"y_values\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the goal: We want to find $x$. The notation $x$ and $y$ might give you the idea that we will somehow solve a matrix system \n",
    "\n",
    "$$Ax = y.$$ \n",
    "But what is the matrix $A$?\n",
    "\n",
    "What we have described is a <b>polynomial approximation problem</b>. For such a problem, the matrix $A$ we need to use is the <i>Vandermonde matrix</i> given by \n",
    "\n",
    "$$A = \\begin{bmatrix} 1 & t_{0} & t_{0}^2 \\\\ 1 & t_{1} & t_{1}^2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & t_{99} & t_{99}^2 \\\\ 1 & t_{100} & t_{100}^2 \\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5b:\n",
    "Although the matrix $A$ looks scary, we have everything we need to make it. Let us do this now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the matrix A\n",
    "\n",
    "# HINT: Look up the np.hstack function. You will need to reshape \n",
    "# the \"t_values\" variable to have shape (101, 1) for this to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have everything we need. However, the system $Ax = y$ is not solvable! There is no second order polynomial that takes exactly the values $y$ at the points in the variable <b>t_values</b>. \n",
    "\n",
    "So what do we do? We use least squares to find the next best thing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use least squares to find the best approximation. Call the resulting variable \"x_values\".\n",
    "\n",
    "# HINT: Remember to use the rcond=None in the linalg.lstsq function. \n",
    "\n",
    "# Print out x_values rounded to 2 decimals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the best approximation with a second-order polynomial is with the function \n",
    "\n",
    "$$p(t) = 2.25 - 2.8t + 1.98t^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5d:\n",
    "To see that it is a good approximation, let us plot it against the scary function $f(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the complicated function f(t)\n",
    "\n",
    "# Plot the second-degree polynomial p(t)\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moral of the Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that NumPy makes working with advanced linear algebra effortlessly. We can then focus on the linear algebra, rather than spending time making our own algorithms. Notice from Exercise 5 that linear algebra can be used to approximate functions as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
